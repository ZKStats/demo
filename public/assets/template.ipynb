{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: zkstats==0.1.6 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (8.1.7)\n",
      "Requirement already satisfied: ezkl==9.1.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (9.1.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.8.2 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (3.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.2 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (1.26.4)\n",
      "Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (2.31.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.11.4 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (1.13.0)\n",
      "Requirement already satisfied: statistics<2.0.0,>=1.0.3 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from zkstats==0.1.6) (1.0.3.5)\n",
      "Requirement already satisfied: filelock in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (2.9.0.post0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from onnx<2.0.0,>=1.15.0->zkstats==0.1.6) (4.25.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->zkstats==0.1.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->zkstats==0.1.6) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->zkstats==0.1.6) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->zkstats==0.1.6) (2024.2.2)\n",
      "Requirement already satisfied: docutils>=0.3 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from statistics<2.0.0,>=1.0.3->zkstats==0.1.6) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.2->zkstats==0.1.6) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch zkstats==0.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from zkstats.core import (\n",
    "    prover_gen_settings,\n",
    "    prover_gen_proof,\n",
    "    setup,\n",
    ")\n",
    "from zkstats.computation import computation_to_model\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# FIXME: fill this in with the path to your data\n",
    "data_path = f\"{cwd}/data.json\"\n",
    "\n",
    "# Paths to the output files\n",
    "output_dir = f\"{cwd}/out\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model_onnx_path = f\"{output_dir}/model.onnx\"\n",
    "compiled_model_path = f\"{output_dir}/model.compiled\"\n",
    "\n",
    "pk_path = f\"{output_dir}/model.pk\"\n",
    "vk_path = f\"{output_dir}/model.vk\"\n",
    "proof_path = f\"{output_dir}/model.pf\"\n",
    "settings_path = f\"{output_dir}/settings.json\"\n",
    "witness_path = f\"{output_dir}/witness.json\"\n",
    "comb_data_path = f\"{output_dir}/comb_data.json\"\n",
    "precal_witness_path = f\"{output_dir}/precal_witness.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data provided shared by the data provider beforehand\n",
    "\n",
    "def get_data_shape(data_path: str) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Get the shape of the data from the data file.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path (str): The path to the data file.\n",
    "\n",
    "    Returns:\n",
    "    - shape_info (dict): A dictionary where keys are column names and values are the number of elements (shape).\n",
    "    \"\"\"\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    shape_info = {col: len(data[col]) for col in data.keys()}\n",
    "    return shape_info\n",
    "\n",
    "data_shape = get_data_shape(data_path)\n",
    "data_commitment_path = f\"{output_dir}/data_commitment.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this should be provided by users\n",
    "selected_columns = [\"x\", \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined Computation\n",
    "\n",
    "A computation should be of type `TComputation`. For example, the following code snippet defines a computation that computes the sum of the private data.\n",
    "\n",
    "```python\n",
    "def computation(state: State, x: list[torch.Tensor]):\n",
    "    out_0 = state.median(x[0])\n",
    "    out_1 = state.median(x[1])\n",
    "    return state.mean(torch.cat([out_0.unsqueeze(0), out_1.unsqueeze(0)]).reshape(-1,1))\n",
    "```\n",
    "\n",
    "FIXME: The following code snippet is entirely from the user. You MUST check\n",
    "1. the code only performs zkstats-related operations.\n",
    "2. the computation must not leak any information about the private data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a dummy computation. Replace it with user's computation\n",
    "import torch\n",
    "from zkstats.computation import State\n",
    "\n",
    "def computation(state: State, x: list[torch.Tensor]):\n",
    "    out_0 = state.median(x[0])\n",
    "    out_1 = state.median(x[1])\n",
    "    return state.mean(torch.cat([out_0.unsqueeze(0), out_1.unsqueeze(0)]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate settings and setup with user's computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generate & Calibrate Setting ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 3, param_scale: 3, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+--------------+--------------+-----------+--------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error   | median_error | max_error | min_error    | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+--------------+--------------+-----------+--------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.012499809 | -0.024999619 | 0         | -0.024999619 | 0.012499809    | 0.024999619      | 0.024999619   | 0             | 0.00031249048      | -0.0005030104      | 0.0005030104           |\n",
      "+--------------+--------------+-----------+--------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale:  [3]\n",
      "setting:  {\"run_args\":{\"tolerance\":{\"val\":0.0,\"scale\":1.0},\"input_scale\":3,\"param_scale\":3,\"scale_rebase_multiplier\":10,\"lookup_range\":[-856,754],\"logrows\":12,\"num_inner_cols\":2,\"variables\":[[\"batch_size\",1]],\"input_visibility\":{\"Hashed\":{\"hash_is_public\":true,\"outlets\":[]}},\"output_visibility\":\"Public\",\"param_visibility\":\"Fixed\",\"div_rebasing\":false,\"rebase_frac_zero_constants\":false,\"check_mode\":\"UNSAFE\"},\"num_rows\":2624,\"total_assignments\":950,\"total_const_size\":421,\"model_instance_shapes\":[[1],[1]],\"model_output_scales\":[0,3],\"model_input_scales\":[3,3],\"module_sizes\":{\"kzg\":[],\"poseidon\":[2624,[2]]},\"required_lookups\":[\"ReLU\",\"Abs\",{\"GreaterThan\":{\"a\":0.0}},{\"Floor\":{\"scale\":16.0}}],\"required_range_checks\":[],\"check_mode\":\"UNSAFE\",\"version\":\"9.1.0\",\"num_blinding_factors\":null,\"timestamp\":1718381959531}\n"
     ]
    }
   ],
   "source": [
    "_, model = computation_to_model(computation, precal_witness_path, isProver=True)\n",
    "prover_gen_settings(\n",
    "    data_path,\n",
    "    selected_columns,\n",
    "    comb_data_path,\n",
    "    model,\n",
    "    model_onnx_path,\n",
    "    [3],\n",
    "    \"resources\",\n",
    "    settings_path,\n",
    ")\n",
    "\n",
    "# Determine which srs to use with the logrows in the settings.json\n",
    "with open(settings_path, \"r\") as f:\n",
    "    settings = json.load(f)\n",
    "logrows = int(settings[\"run_args\"][\"logrows\"])\n",
    "srs_path = f'~/.ezkl/srs/kzg{logrows}.srs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n",
      "Time setup: 0.8122658729553223 seconds\n"
     ]
    }
   ],
   "source": [
    "setup(model_onnx_path, compiled_model_path, settings_path, vk_path, pk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate proof with your data and user's computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Generating Witness ====\n",
      "witness boolean:  1.0\n",
      "witness result 1 : 24.875\n",
      "==== Generating Proof ====\n",
      "proof:  {'instances': [['3bea079e2a500a3285d05fd174263a5ffd78c2dd63131c52abd2a199f786f601', '8ef07c3e2daefe521c14b14bc10f91b50ea0d110db70b3192443c6f25d1cd124', '0100000000000000000000000000000000000000000000000000000000000000', 'c700000000000000000000000000000000000000000000000000000000000000']], 'proof': '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', 'transcript_type': 'EVM'}\n",
      "Time gen prf: 1.0643398761749268 seconds\n"
     ]
    }
   ],
   "source": [
    "prover_gen_proof(\n",
    "    model_onnx_path,\n",
    "    comb_data_path,\n",
    "    witness_path,\n",
    "    compiled_model_path,\n",
    "    settings_path,\n",
    "    proof_path,\n",
    "    pk_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the proof to ensure it is correct\n",
    "NOTE: The following section is to illustrate what should be done on the user (data consumer) side. This step is not required by the data provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n",
      "Time setup: 0.8539810180664062 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24.875]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def create_dummy(shape_info: Dict[str, int], dummy_data_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a dummy data file with randomized data based on the provided shape information.\n",
    "\n",
    "    Parameters:\n",
    "    - shape_info (dict): A dictionary where keys are column names and values are the number of elements (shape).\n",
    "    - dummy_data_path (str): The path to save the dummy data file.\n",
    "    \"\"\"\n",
    "    dummy_data = {}\n",
    "    for col, length in shape_info.items():\n",
    "        # Generate random data for each column\n",
    "        dummy_data[col] = np.round(np.random.uniform(0, 100, length), 1).tolist()\n",
    "\n",
    "    with open(dummy_data_path, 'w') as f:\n",
    "        json.dump(dummy_data, f)\n",
    "\n",
    "\n",
    "from zkstats.core import verifier_define_calculation, verifier_verify\n",
    "\n",
    "verifier_model_path = f\"{output_dir}/verifier_model.onnx\"\n",
    "verifier_compiled_model_path = f\"{output_dir}/verifier_model.compiled\"\n",
    "verifier_vk_path = f\"{output_dir}/verifier_model.vk\"\n",
    "verifier_pk_path = f\"{output_dir}/verifier_model.pk\"\n",
    "dummy_data_path = f\"{output_dir}/dummy_data.json\"\n",
    "sel_dummy_data_path = f\"{output_dir}/sel_dummy_data.json\"\n",
    "\n",
    "# NOTE: generate the verifier model with the `precal_witness_path` provided by the prover\n",
    "_, verifier_model = computation_to_model(computation, precal_witness_path, isProver=False)\n",
    "# create dummy data with the same shape as the original data\n",
    "create_dummy(data_shape, dummy_data_path)\n",
    "# generate the verifier model given the dummy data and the selected columns\n",
    "verifier_define_calculation(dummy_data_path, selected_columns, sel_dummy_data_path, verifier_model, verifier_model_path)\n",
    "# generate the verification key\n",
    "setup(verifier_model_path, verifier_compiled_model_path, settings_path, verifier_vk_path, verifier_pk_path)\n",
    "# verify the proof\n",
    "verifier_verify(proof_path, settings_path, verifier_vk_path, selected_columns, data_commitment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the file paths. You should share the following files back to the user for them to verify the proof. You **SHOULD NOT** share more files otherwise data might be leaked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model onnx:\t\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/model.onnx\n",
      "Settings:\t\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/settings.json\n",
      "Proof:\t\t\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/model.pf\n",
      "Verification key:\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/model.vk\n",
      "Srs path:\t\t ~/.ezkl/srs/kzg12.srs\n"
     ]
    }
   ],
   "source": [
    "print(\"Model onnx:\\t\\t\", model_onnx_path)\n",
    "print(\"Settings:\\t\\t\", settings_path)\n",
    "print(\"Proof:\\t\\t\\t\", proof_path)\n",
    "print(\"Verification key:\\t\", vk_path)\n",
    "print(\"Srs path:\\t\\t\", srs_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
